---
layout: default
---
<div class="portfolio_text">
<img src="./images/profile_pic.jpg" alt="Anastasia's profile photo" width="28%">

<div class="emoj">
â€‹<span>Hi, I'm Anastasia ðŸ‡ºðŸ‡¦ ðŸ‡¨ðŸ‡¦! I am a PhD student at the <a href="http://learning.cs.toronto.edu/">University of Toronto</a> and <a href="https://vectorinstitute.ai/">Vector Institute</a>. I am fortunate to be working
     with <a href="https://thedonnellycentre.utoronto.ca/faculty/brenda-andrews/">Brenda Andrews</a>, <a href="https://thedonnellycentre.utoronto.ca/faculty/charles-boone">Charlie Boone</a>
      and <a href="https://vectorinstitute.ai/team/jimmy-ba/">Jimmy Ba</a>.
     My research focus is <strong>representation learning</strong>, <strong>natural language processing</strong> and application of these areas to <strong>biomedical ML</strong>.
    Throughout my PhD, I interned at
    </span>
    <img src="./images/meta_icon2.png" width="18px">

    <span>
    <a href="https://ai.facebook.com/research/">Meta (Facebook) AI </a>,
    </span>

    <img src="./images/amazon_icon.png" width="18px">
    <span>
    <a href="https://ai.facebook.com/research/">Amazon Research </a>, and
    </span>
    <img src="./images/recursion_icon2.png" width="16px">
    <span>
    <a href="https://www.recursion.com/">Recursion Pharmaceuticals</a>.
    More details in my  <a href="https://arazd.github.io/CV_Nov2022.pdf">CV</a>.
    </span>
</div>â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹
<!-- <div>
<span class="emoji">
Hi, I'm Anastasia ðŸ‡ºðŸ‡¦ ðŸ‡¨ðŸ‡¦! I am a PhD student at the <a href="http://learning.cs.toronto.edu/">University of Toronto</a> and <a href="https://vectorinstitute.ai/">Vector Institute</a>. I am fortunate to be working
 with <a href="https://thedonnellycentre.utoronto.ca/faculty/brenda-andrews/">Brenda Andrews</a> and <a href="https://vectorinstitute.ai/team/jimmy-ba/">Jimmy Ba</a>.
Throughout my PhD, I interned at</span>

<span class="emoji"><img src="./images/meta_icon.jpeg" width="16px"></span>

<span class="emoji"> <a href="https://ai.facebook.com/research/">Meta (Facebook) AI </a>,</span>
<span class="emoji"><img src="./images/amazon_icon.png" width="16px"></span>
<span class="emoji"><a href="https://www.amazon.science/research-areas/conversational-ai-natural-language-processing">Amazon Research</a>
and <a href="https://www.recursion.com/">Recursion Pharmaceuticals</a>.
More details in my  <a href="https://arazd.github.io/CV.pdf">CV</a>.
</span>
</div> -->

 <!-- You can contact me at <a href="mailto:anastasia.razdaibiedina@mail.utoronto.ca">email me</a>!<br> -->
  <div class="icon">
    <a href="https://ca.linkedin.com/in/anastasia-razdaibiedina-438929197"><img src="./images/linkedin_icon.png" width="24px"></a>
    <a href="https://github.com/arazd"><img src="./images/github_icon.png" width="24px"></a>
    <a href="https://scholar.google.com/citations?user=1whPOfwAAAAJ&hl=en"><img src="./images/google_scholar_icon.png" width="24px"></a>
    <a href="mailto:anastasia.razdaibiedina@mail.utoronto.ca"><img src="./images/email_icon.png" width="24px"></a>
  </div>
</div>

<h2>Research </h2>
I am interested in developing robust algorithms that can succeed in solving tasks in "real-world" setting,
including learning under limited labels, data distribution shift and on multiple tasks.
<!-- that can learn meaningful representations from the real-world data,
while being resistant to forgetting and inherent data noise. -->
The key topics I am currently focusing on are:
<ul>
  <li> <strong>Efficiency and scalability</strong>: how can we make deep learning models more efficient?
    I am particularly interested in parameter-efficient learning and training with limited labels
    (<a href="https://openreview.net/pdf?id=UJTgQBc91_">Progressive Prompts</a>, <a href="#PIFiA">PIFiA</a>).
  <!-- <li> <strong>Generalist models</strong>: most existing approaches excel in learning a single task, yet are not so effective in generalizing for future tasks or multiple datasets.
    How can we build models that can generalize to never-before-seen data and tasks?
    (<a href="">Representation Consistency Targets</a>, <a href="">Multi-defect microscopy image restoration</a>)-->
  <li> <strong>Lifelong learning</strong>: humans can learn on a variety of tasks while gaining experience and avoiding forgetting.
    My goal is to develop effective lifelong learning methods inspired by the core principles of human thinking
    (<a href="https://openreview.net/pdf?id=UJTgQBc91_">Progressive Prompts</a>, <a href="https://arxiv.org/pdf/2205.11603.pdf">Representation Consistency Targets</a>).

</ul>
<span id="Papers">Some of my works:</span>
<br>
<br>
<!--
<img src="./images/pifia.png" alt="PIFiA illustration" width="20%">
<div class="paper_title">PIFiA: a self-supervised approach for discovery of protein functional
  fingerprints from single-cell imaging data</div>
<div class="authors"> <strong>A. Razdaibiedina</strong>, A. Brechalov, H. Friesen, M. Mattiazzi-Usaj, H. Suresh, K. Wang, C. Boone, J. Ba, B. Andrews
</div>
<div class="submission_info">
  To be submitted to Nature Methods (Dec 2021)
</div>
-->
<div>
      <img class="float" src="./images/prog_prompt.png" alt="CAPCORT illustration">
      <div class="portfolio_text">
        <div class="paper_title">Progressive Prompts: continual learning in language models</div>
        <div class="authors"> <strong>A Razdaibiedina</strong>, Y Mao, R Hou, M Khabsa, M Lewis, A Almahairi
        </div>
        <div class="submission_info">
          Preprint, 2022
        </div>
        <div class="authors">
          <a href="https://openreview.net/pdf?id=UJTgQBc91_">Paper</a>&emsp;
          Code (to be released soon!) &emsp;
        </div>
      </div>
</div>
<br><br>
<div>
      <img class="float" src="./images/repina2.png" alt="REPINA illustration">
      <div class="portfolio_text">
        <div class="paper_title">Improving language models fine-tuning with representation consistency targets</div>
        <div class="authors"> <strong>A Razdaibiedina</strong>, V Madan, Z Karnin, A Khetan, V Kapoor
        </div>
        <div class="submission_info">
          Preprint, 2022
        </div>
        <div class="authors">
          <a href="https://arxiv.org/pdf/2205.11603.pdf">Paper</a>&emsp;
          Code (to be released soon!) &emsp;
        </div>
      </div>
</div>
<br><br>
<div>
      <img class="float" src="./images/pifia.png" alt="PIFiA illustration">
      <div class="portfolio_text" id="PIFiA">
        <div class="paper_title">PIFiA: a self-supervised approach for discovery of protein functional
          fingerprints from single-cell imaging data</div>
        <div class="authors"> <strong>A Razdaibiedina</strong>, A Brechalov, H Friesen, M Mattiazzi-Usaj, HG Suresh, K Wang, C Boone, J Ba, B Andrews
        </div>
        <div class="submission_info">
          In submission to Nature Methods
        </div>
      </div>
</div>
<br><br>
<div>
      <img class="float" src="./images/deeploc_representations.png" alt="ICLR 2022 MLDD paper">
      <div class="portfolio_text">
        <div class="paper_title">Learning multi-scale functional representations of proteins from single-cell microscopy data</div>
        <div class="authors"> <strong>A Razdaibiedina</strong>, A Brechalov
        </div>
        <div class="submission_info">
          ICLR 2022, MLDD
        </div>
        <div class="authors">
          <a href="https://openreview.net/forum?id=FRbxL6JvUXz">Paper</a>&emsp;
          <a href="https://github.com/arazd/protein_representation_learning">Code</a>&emsp;
          <a href="https://github.com/arazd/protein_representation_learning/blob/main/poster.jpeg">Poster</a>
        </div>
      </div>
</div>
<br><br>
<div>
      <img class="float" src="./images/t2.png" alt="CONCORT illustration">
      <div class="portfolio_text">
        <div class="paper_title">Multi-defect microscopy image restoration under limited data conditions</div>
        <div class="authors"> <strong>A Razdaibiedina</strong>, J Velayutham, M Modi
        </div>
        <div class="submission_info">
          NeurIPS 2019, Medical Imaging workshop (rated in top-15 submissions)
        </div>
        <div class="authors">
          <a href="https://arxiv.org/pdf/1910.14207.pdf">Paper</a>&emsp;
          <a href="https://github.com/arazd/MicroscopyGAN">Code</a>&emsp;
          <a href="https://github.com/arazd/MicroscopyGAN/blob/master/poster.pdf">Poster</a>
        </div>
      </div>
</div>
<br>

<h2 id="Experience">Experience</h2>
<ul>
  <li><span class="emoj"><img src="./images/meta_icon2.png" width="18px"></span>
    <strong>Meta (Facebook) AI</strong> <br>
  Research Intern, AI Integrity & FAIR<br>
  Jun 2022 - Present<br>
  Team: <a href="https://scholar.google.ca/citations?user=WbYAa7IAAAAJ&hl=en">Amjad Almahairi</a>, <a href="https://scholar.google.co.uk/citations?user=SnQnQicAAAAJ&hl=en">Mike Lewis</a>, <a href="https://scholar.google.com/citations?user=V9JYPP0AAAAJ&hl=en">Madian Khabsa</a>, <a href="https://scholar.google.com/citations?user=steJe6IAAAAJ&hl=en">Yuning Mao</a>, <a href="https://scholar.google.com/citations?user=PKHKqX0AAAAJ&hl=en">Rui Hou</a><br>
  <span class="authors">Technologies: T5 model, BERT model, prompt tuning <br>
  Toolkit: pytorch, huggingface, numpy, pandas, jupyter, matplotlib, bash, slurm, git</span> </li>

  <br>

  <li>
    <span class="emoj"><img src="./images/amazon_icon.png" width="18px"></span>
  <strong>Amazon Research</strong><br>
  Research Intern, AWS<br>
  May 2021 - Oct 2021<br>
  Team: <a href="https://www.amazon.science/author/vivek-madan">Vivek Madan</a>, <a href="https://scholar.google.com/citations?user=pK2kQvgAAAAJ&hl=en">Daniel Khashabi</a>, <a href="https://scholar.google.com/citations?user=AaauqDAAAAAJ&hl=en">Ashish Khetan</a>, Vishaal Kapoor, <a href="https://scholar.google.co.il/citations?user=aUsrzjgAAAAJ&hl=en">Zohar Karnin</a><br>
  Project: <i>Stabilizing Fine-tuning of Language Models</i><br>
  <span class="authors">Technologies: BERT model, RoBERTa model, regularization, fine-tuning <br>
  Toolkit: tensorflow, huggingface, numpy, pandas, scikit learn, bash, aws cloud computing</span> </li>
  <br>

  <li><span class="emoj"><img src="./images/recursion_icon2.png" width="18px"></span>
    <strong>Recursion Pharmaceuticals</strong><br>
  Data Science Intern, Computational Drug Discovery<br>
  Team: <a href="https://www.linkedin.com/in/jesford/">Jes Ford</a>, <a href="https://scholar.google.com/citations?user=xHNHuD0AAAAJ&hl=en">Berton Earnshaw</a>, <a href="https://scholar.google.com/citations?user=gxL1qj8AAAAJ&hl=en">Jason Yosinski</a>, <a href="https://scholar.google.com/citations?user=Cp_wDj4AAAAJ&hl=en">Imran Haque</a><br>
  Jun 2020 - Sep 2020<br>
  Project: <i>Representation Learning for Drug Discovery</i><br>
  <span class="authors">Technologies: ResNet, DenseNet, data augmentation (MixUp, CutMix)<br>
  Toolkit: pytorch, determined, scikit learn, numpy, pandas, seaborn, plotly, jupyter notebook, bash, git, google cloud</span </li>

</ul>


<h2>Talks</h2>

<ul>
  <li>Talk at FAIR: continual learning for language models without forgetting
    <br><div class="authors">Facebook AI Research, Seattle & Menlo Park, Sep 2022
      <!-- <span class="authors"><a href="https://www.youtube.com/watch?v=lqcyrCazgc8">video</a></span></div> -->
  </li>
  <br>

  <li>TorBUG talk: PIFiA, a self-supervised approach for protein functional discovery
    <br><div class="authors">Toronto Bioinformatics User Group, Mar 2022 <span class="authors"><a href="https://www.youtube.com/watch?v=lqcyrCazgc8">video</a></span></div>
  </li>
  <br>

  <li>Discovering gene-disease relationships with Deep Learning
    <br><div class="authors">Temerty Centre for Artificial Intelligence Research and Education in Medicine, Aug 2021 <span class="authors"><a href="https://www.youtube.com/watch?v=GZr0XwrPRwU">video</a></span></div>

  </li>
  <br>
  <li>Panel discussion: AI in Healthcare and Future
    <br><div class="authors">York University x Vector Institute, Oct 2019
      <span class="authors"><a href="https://www.youtube.com/watch?v=iaErgR_umkA">video</a></span>
    </div>
  </li>
  <!-- <li>Finalist talk @ Falling Walls Lab Kyiv</li> -->
</ul>


<h2>Teaching</h2>
I had wonderful opportunities to teach several ML courses at University of Toronto and Vector Institute:
<ul>
<li> <a href="https://vectorinstitute.ai/2022/09/07/bias-in-ai-program-showing-businesses-how-to-reduce-bias-and-mitigate-risk/">BAI</a>: Bias in AI, Vector Institute (Winter 2022) </li>
<li> <a href="https://artsci.calendar.utoronto.ca/course/csc384h1">CSC384</a>: Introduction to Artificial Intelligence, UofT CS (Winter 2021) </li>
<li> <a href="https://vectorinstitute.ai/programs-courses/ai-certificate-courses/">DL2</a>: Deep Learning 2 for Industry Professionals, Vector Institute (Fall 2020) </li>
<li> <a href="https://erdogdu.github.io/csc311_f19/">CSC311</a>: Introduction to Machine Learning, UofT CS (Fall 2019) </li>
</ul>


<h2>Selected Honors & Awards</h2>
<ul>
<li> <a href="https://en.wikipedia.org/wiki/Ontario_Graduate_Scholarship">Ontario Graduate Scholarship</a>, 2021-2022</li>
<li> <a href="https://vectorinstitute.ai/2019/03/25/vector-institute-welcomes-new-postgraduate-affiliates-to-its-growing-research-community/">Vector Institute PGA Fellowship</a>, 2019, 2020, 2021</li>
<!-- <li> NVIDIA GPU Grant, 2018</li> -->
<li> University of Toronto Ph.D. Merit Entrance Scholarship, 2018</li>

</ul>

<h2>Contact</h2>
I am happy to get in touch! Please contact me at <i>anastasia.razdaibiedina [at] mail.utoronto.ca</i> or connect on <a href="https://ca.linkedin.com/in/anastasia-razdaibiedina-438929197">LinkedIn</a>.

</br>
</br>
<!-- <div class="posts">
  {% for post in site.posts %}
    <article class="post">

      <h1><a href="{{ site.baseurl }}{{ post.url }}">{{ post.title }}</a></h1>

      <div class="entry">
        {{ post.excerpt }}
      </div>

      <a href="{{ site.baseurl }}{{ post.url }}" class="read-more">Read More</a>
    </article>
  {% endfor %}
</div> -->
